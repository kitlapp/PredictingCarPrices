{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d031b48-d976-41c8-aeb5-4b8b5907c2a6",
   "metadata": {},
   "source": [
    "# Predicting Used Car Prices Using Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176257e1-c70b-4b0d-8028-a28a8d586a1e",
   "metadata": {},
   "source": [
    "## Environment Management"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5d0fc3b1-5362-4a42-8ed2-870e215aa771",
   "metadata": {},
   "source": [
    "Please read the project's README for instructions on how to set up the project's environment on your computer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a49d9b-1a65-4de0-b1d6-d4b7e80fe5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966fd93d-06cc-41c0-83dc-e4ee0c55e80b",
   "metadata": {},
   "source": [
    "# Import Basic Libraries and Read the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94eebccd-9d90-4a82-a5e0-80612f8d95fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # For numerical operations and arrays.\t\n",
    "import pandas as pd  # For data manipulation and analysis.\t\n",
    "import matplotlib.pyplot as plt  # For basic plotting.\t\n",
    "import seaborn as sns  # For enhanced plotting.\t\n",
    "import plotly.express as px  # For interactive plotting.\t\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor  # For calculating vif and check for features multicolinearity.\n",
    "from sklearn.preprocessing import StandardScaler  # For creating scaler instances for standardization purposes.\n",
    "from sklearn.model_selection import train_test_split  # For splitting the data into sets avoiding overfitting.\n",
    "from sklearn.linear_model import LinearRegression  # For creating LinearRegression instances.\n",
    "\n",
    "sns.set()  # For overriding default matplotlib styles with those of seaborn.\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4167bc-b5ee-4f4c-99e1-e3cd7be6e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file in a Data Frame:\n",
    "raw = pd.read_csv('original.csv')\n",
    "raw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e538f0-c608-42c6-b189-e7895dda114d",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "This data set concerns used cars. The most interesting variable, or our target, is the price of these cars. Consequently, all the other columns may be potential features that could influence the price and may provide explanatory power on price levels.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d734e088-2106-45bd-8bc8-217a1d336f60",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af672fae-cead-4c90-94bf-adb0898ad59a",
   "metadata": {},
   "source": [
    "## Drop Nulls and Unecessary Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfcd71d-de56-4a5c-b9d3-89414f2aec1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw.describe(include='all').transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea41593-88c1-4a18-a08e-88ca5f38891e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function showing information of nulls in the data set:\n",
    "def create_table_of_nulls(rawdata):\n",
    "    null_counts = rawdata.isnull().sum()  # Sums only the \"True\" values (the nulls).\n",
    "    columns_with_nulls = null_counts[null_counts > 0].to_frame().reset_index()  # Keep the columns with nulls and turn to a df.\n",
    "    columns_with_nulls.columns = ['Columns with Nulls', 'Null Count']  # Name the columns with nulls.\n",
    "    columns_with_nulls['Null Percent %'] = (columns_with_nulls['Null Count'] / raw.shape[0]) * 100   # Create the percent of nulls column.\n",
    "    print(columns_with_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ddb376-abb1-4aef-9cf2-52fd8a41362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table_of_nulls(rawdata=raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3186278-34c1-479b-be1e-5adff056cde2",
   "metadata": {},
   "source": [
    "Since the observations are less than 5% we 'll remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d94974-c7ab-4584-8ca0-3f1ee919d0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df dropping the null observations of the raw data:\n",
    "raw_drop_obs = raw.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0439e349-3fb6-4ac6-91d7-42f790664282",
   "metadata": {},
   "source": [
    "\"Registration\" column has only two unique values from which the value \"yes\" concerns almost the 91% of the dataset. We 'll drop the whole column as it doesn't probably adds explanatory power."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b4898b-e58c-45df-81d2-e7753c392456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the \"Registration\" column:\n",
    "raw_drop_reg = raw_drop_obs.drop(columns='Registration', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c874af4-4ad0-49a2-a67d-d407122ce73d",
   "metadata": {},
   "source": [
    "## Price Column Outliers Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97cac7c3-a6c5-4b74-8e79-9c8a94fee561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the double image figure with two rows and one column:\n",
    "fig, (box, hist) = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "# Create the first image (boxplot):\n",
    "sns.boxplot(data=raw_drop_reg, x='Price', ax=box)\n",
    "\n",
    "# Create the second image (histplot):\n",
    "sns.histplot(data=raw_drop_reg['Price'], ax=hist, bins=100)\n",
    "\n",
    "# Set the title of the images:\n",
    "box.set(title='Boxplot of Price')\n",
    "hist.set(title='Histogram of Price')\n",
    "\n",
    "# Adjust the layout to prevent overlapping of labels: \n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig('boxhist.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d2318e8-336f-4e83-9338-12b7cdf99825",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "There is a large number of outliers which are very close to the upper whisker. It may not be appropriate to drop all outliers. However, there are some outliers which are very far from the others. To simplify the process, let's drop the top 1% of price observations and check what happens.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b739d7a-7614-4e9a-abe8-8e77caaf5663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the value of 99th quantile:\n",
    "top_1percent_outliers = raw_drop_reg[\"Price\"].quantile(0.99)\n",
    "\n",
    "# Keep all values smaller than the value of 99th quantile:\n",
    "raw_price_outl_removed = raw_drop_reg[raw_drop_reg['Price'] < top_1percent_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ba7f82-885f-4dd6-91a7-dc6f285e94cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the double image figure with two rows and one column:\n",
    "fig, (box, hist) = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "# Create the first image (boxplot):\n",
    "sns.boxplot(data=raw_price_outl_removed, x='Price', ax=box)\n",
    "\n",
    "# Create the second image (histplot):\n",
    "sns.histplot(data=raw_price_outl_removed['Price'], ax=hist, bins=100)\n",
    "\n",
    "# Set the title of the images:\n",
    "box.set(title='Final Boxplot of Price')\n",
    "hist.set(title='Final Histogram of Price')\n",
    "\n",
    "# Adjust the layout to prevent overlapping of labels: \n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig('boxhist2.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6a36c0-b400-444f-817d-5286f3653c06",
   "metadata": {},
   "source": [
    "Dropping only the top 1% of price observations we managed to drop the max price from 300K to approximately 129K, i.e., approximately 57%!  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f7b913c-66e4-432a-9a29-2aa69ca9cda4",
   "metadata": {},
   "source": [
    "## Mileage Column Outlier Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc223472-18ba-4919-9d8b-9f6a7571c4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the double image figure with two rows and one column:\n",
    "fig, (box, hist) = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "# Create the first image (boxplot):\n",
    "sns.boxplot(data=raw_price_outl_removed, x='Mileage', ax=box)\n",
    "\n",
    "# Create the second image (histplot):\n",
    "sns.histplot(data=raw_price_outl_removed['Mileage'], ax=hist, bins=100)\n",
    "\n",
    "# Set the title of the images:\n",
    "box.set(title='Boxplot of Mileage')\n",
    "hist.set(title='Histogram of Mileage')\n",
    "\n",
    "# Adjust the layout to prevent overlapping of labels: \n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig('boxhist3.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cc81aa-db22-4f1f-b687-af00c6385907",
   "metadata": {},
   "source": [
    "Let's drop the top 1% of mileage observations and see what happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa7486b-cabf-4654-880b-997c7e04ce6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the value of 99th quantile:\n",
    "top_1percent_outliers = raw_price_outl_removed['Mileage'].quantile(0.99)\n",
    "\n",
    "# Keep all values smaller than the value of 99th quantile:\n",
    "raw_mileage_outl_removed = raw_price_outl_removed[raw_price_outl_removed['Mileage'] < top_1percent_outliers]\n",
    "\n",
    "# Rearrange the index:\n",
    "raw_mileage_outl_removed = raw_mileage_outl_removed.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b2c8a2-bf27-4c06-9a92-48b59221d4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the double image figure with two rows and one column:\n",
    "fig, (box, hist) = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "# Create the first image (boxplot):\n",
    "sns.boxplot(data=raw_mileage_outl_removed, x='Mileage', ax=box)\n",
    "\n",
    "# Create the second image (histplot):\n",
    "sns.histplot(data=raw_mileage_outl_removed['Mileage'], ax=hist, bins=100)\n",
    "\n",
    "# Set the title of the images:\n",
    "box.set(title='Final Boxplot of Mileage')\n",
    "hist.set(title='Final Histogram of Mileage')\n",
    "\n",
    "# Adjust the layout to prevent overlapping of labels: \n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig('boxhist4.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b87aaf-fe90-443a-bedc-c1d1c61863d2",
   "metadata": {},
   "source": [
    "Dropping only the top 1% of milage outliers reduced its max value from 980 to 435, i.e., 55.61%!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e7edde0-b9b8-40c3-8e99-67bb2bb97c6b",
   "metadata": {},
   "source": [
    "## Engine Volume Column Outlier Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33895b7c-f8cc-45fb-8bf6-2348ca26601a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the double image figure with two rows and one column:\n",
    "fig, (box, hist) = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "# Create the first image (boxplot):\n",
    "sns.boxplot(data=raw_mileage_outl_removed, x='EngineV', ax=box)\n",
    "\n",
    "# Create the second image (histplot):\n",
    "sns.histplot(data=raw_mileage_outl_removed['EngineV'], ax=hist, bins=30)\n",
    "\n",
    "# Set the title of the images:\n",
    "box.set(title='Boxplot of Engine Volume')\n",
    "hist.set(title='Histogram of Engine Volume')\n",
    "\n",
    "# Adjust the layout to prevent overlapping of labels: \n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig('boxhist5.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daf3882-dbdf-4af1-8638-802b8baeaec6",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "The most commercial cars engine volume fall in range of 1-3 liters. We can expand this range to 0.6 to 8 liters because Bugatti Veyron Super Sport features an 8 liter engine. Let's just for curiosity manually check to see the cars with the larger engine volumes keeping in mind that the most correct range for engine volume might be 0.6 to 6.3 or maybe 6.5. The rest of the values are wrong imports.  \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6628d9-8ab3-471f-820f-70b10965148e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the 30 largest engine volume values:\n",
    "raw_mileage_outl_removed['EngineV'].sort_values(ascending=False).to_frame().head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e138f7-ddfc-401d-bcfc-5acca67a89f0",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "From the df above, all values which are larger than 9 liters can be considered wrong. It can be seen that there are a lot of entries with 6.3 liters of volume. Since, this entry is lied in the reasonable range it is possibly correct. However, there is only one value of 6.5 liters, although it is in range and two other values (7.2 and 9). Let's isolate this indexes here to check them: 3762: 6.5, 1506: 7.2, 2974: 9. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7487fb9e-ad0d-4e09-8a53-37e4f83d3b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the observations lie in the upper range limit:\n",
    "print(\"6.5 Liters Observation:\", raw_mileage_outl_removed.iloc[3762], \"7.2 Liters Observation:\", raw_mileage_outl_removed.iloc[1506], \"9 Liters Observation:\", raw_mileage_outl_removed.iloc[2974],)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c7041-a02b-4194-a666-c3a0ebb4f91a",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "The observation 3762 is a Mercedes-Benz S65 AMG (2008) which volume is given to be at 6 liters which is very close to 6.5 liters of the data table. The observation 1506 is a Toyota Corolla (2011) with an engine volume of 1.8 liters. This is wrong for sure. Finally, the observation 2974 is a Volkswagen Passat B6 (2010) which is impossible to has a 9 liter engine. From this mini research, it is concluded that all observations above and equal to 6.5 liters should be dropped. In addition, some observations with 6.3 liters were checked and seemed to be ok ensuring the conclusion we ended up with.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64631ff-c779-48fe-8ae5-5dafe6bb245c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep all values which are smaller than the value of 6.5 liters:\n",
    "raw_enginev_removed = raw_mileage_outl_removed[raw_mileage_outl_removed['EngineV'] < 6.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5458fd7c-0643-42d6-8152-87dc6c565e1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the double image figure with two rows and one column:\n",
    "fig, (box, hist) = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "# Create the first image (boxplot):\n",
    "sns.boxplot(data=raw_enginev_removed, x='EngineV', ax=box)\n",
    "\n",
    "# Create the second image (histplot):\n",
    "sns.histplot(data=raw_enginev_removed['EngineV'], ax=hist, bins=30)\n",
    "\n",
    "# Set the title of the images:\n",
    "box.set(title='Final Boxplot of Engine Volume')\n",
    "hist.set(title='Final Histogram of Engine Volume')\n",
    "\n",
    "# Adjust the layout to prevent overlapping of labels: \n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig('boxhist6.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ad3f3d-d15d-422f-820f-f0a285779447",
   "metadata": {},
   "source": [
    "## Year Column Outlier Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8088e50-bf8d-451b-a2d1-d56334142abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the double image figure with two rows and one column:\n",
    "fig, (box, hist) = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "# Create the first image (boxplot):\n",
    "sns.boxplot(data=raw_enginev_removed, x='Year', ax=box)\n",
    "\n",
    "# Create the second image (histplot):\n",
    "sns.histplot(data=raw_enginev_removed['Year'], ax=hist, bins=30)\n",
    "\n",
    "# Set the title of the images:\n",
    "box.set(title='Boxplot of Year')\n",
    "hist.set(title='Histogram of Year')\n",
    "\n",
    "# Adjust the layout to prevent overlapping of labels: \n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig('boxhist7.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05117f5b-1a89-4163-9797-cef746132b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the value of 99th quantile:\n",
    "bottom_1percent_outliers = raw_enginev_removed['Year'].quantile(0.01)\n",
    "\n",
    "# Keep all values smaller than the value of 99th quantile:\n",
    "raw_year_outl_removed = raw_enginev_removed[raw_enginev_removed['Year'] > bottom_1percent_outliers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7984ddaf-ea74-48ed-8622-30cd6d60ef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the double image figure with two rows and one column:\n",
    "fig, (box, hist) = plt.subplots(2, 1, sharex=True, figsize=(10, 8))\n",
    "\n",
    "# Create the first image (boxplot):\n",
    "sns.boxplot(data=raw_year_outl_removed, x='Year', ax=box)\n",
    "\n",
    "# Create the second image (histplot):\n",
    "sns.histplot(data=raw_year_outl_removed['Year'], ax=hist, bins=30)\n",
    "\n",
    "# Set the title of the images:\n",
    "box.set(title='Final Boxplot of Year')\n",
    "hist.set(title='Final Histogram of Year')\n",
    "\n",
    "# Adjust the layout to prevent overlapping of labels: \n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig('boxhist8.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f654f1f2-1d4e-48b9-bd1a-5e04525e213e",
   "metadata": {},
   "source": [
    "Dropping the bottom 1% of year outliers, we managed to reduce the year range by 40.42%!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8384cfb-714f-46f4-a043-817ddff6a9b9",
   "metadata": {},
   "source": [
    "We dropped the 11% of observations in total. However, we managed to get rid of all null values, the outliers and the wrong values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb18c90-ec5d-42ab-92dc-fbe5f92eb33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final, cleaned df:\n",
    "df = raw_year_outl_removed.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bae1db4d-d002-430f-b566-be176964ff4a",
   "metadata": {},
   "source": [
    "## Save the Cleaned Data Frame Including all its Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb46e6d-7968-4390-ae9f-175e4e5665f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'cleaned.csv'\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae13b0e4-ac17-4664-86a8-f97db777b2a0",
   "metadata": {},
   "source": [
    "# Check Linear Regression Assumptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcf8792-461d-46f1-b5fa-4bedef437d9e",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Only the continuous features can influence the assumptions application. The rest of the features, the categorical ones are considered generally safe for the assumptions to be hold and can be exluded. Consequently, there 4 features of interest for these checks: Price, mileage, the year of the model and engine volume whereas the prices is the target variable.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "261ac76d-e50f-4d09-9928-00dbaa430a30",
   "metadata": {},
   "source": [
    "## Check for Linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4ccec9-d364-4512-b6dd-add35b7c4038",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the triple image figure with one row and three columns:\n",
    "fig, (mileage, year, volume) = plt.subplots(1, 3, sharey=True, figsize=(15, 8))\n",
    "\n",
    "# Create the first image (mileage) and set its title:\n",
    "mileage.scatter(df['Mileage'], df['Price'])\n",
    "mileage.set_title('Price VS Mileage')\n",
    "\n",
    "# Create the second image (mileage) and set its title:\n",
    "year.scatter(df['Year'], df['Price'])\n",
    "year.set_title('Price VS Year')\n",
    "\n",
    "# Create the third image (mileage) and set its title:\n",
    "volume.scatter(df['EngineV'], df['Price'])\n",
    "volume.set_title('Price VS Engine Volume')\n",
    "\n",
    "# Adjust the layout to prevent overlapping of labels: \n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig('scatterplots.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d61bb-2e6e-4e3f-a2b2-60f670c1f8eb",
   "metadata": {},
   "source": [
    "The data showcases more of an exponential pattern than a linear one. Let's transform the price data and dee the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90960a2f-9eaa-47ef-a084-a5f1e519e7f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the price values to logarithmic ones:\n",
    "df['Price'] = np.log(df['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea2df19-86f5-4a1b-b7dc-60bff8c73154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the triple image figure with one row and three columns:\n",
    "fig, (mileage, year, volume) = plt.subplots(1, 3, sharey=True, figsize=(15, 8))\n",
    "\n",
    "# Create the first image (mileage) and set its title:\n",
    "mileage.scatter(df['Mileage'], df['Price'])\n",
    "mileage.set_title('Log Price VS Mileage')\n",
    "\n",
    "# Create the second image (mileage) and set its title:\n",
    "year.scatter(df['Year'], df['Price'])\n",
    "year.set_title('Log Price VS Year')\n",
    "\n",
    "# Create the third image (mileage) and set its title:\n",
    "volume.scatter(df['EngineV'], df['Price'])\n",
    "volume.set_title('Log Price VS Engine Volume')\n",
    "\n",
    "# Adjust the layout to prevent overlapping of labels: \n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig('scatterplotsLog.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e344106-e005-4a6c-8415-cbb43efa9c00",
   "metadata": {},
   "source": [
    "Linear patterns can be seen in the above data. So the first assumption is solved."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e577563e-4aea-47b7-8638-11f5d1a77023",
   "metadata": {},
   "source": [
    "## Check for No-Endogeneity of Regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93757b59-690a-4299-8edf-57714d7888e7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Whatever might affect the error, will be properly examined, as long as all the features are included in the model. We will include all the features discussing about endogeneity after the application of the model and the knowledge of the adjusted R-Squared. We will see what might be done then. So, this assumption holds for now as well. \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5951f4-09e7-4cc6-a06b-8bf676c38246",
   "metadata": {},
   "source": [
    "## Check for Normality of Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848a6639-ba6b-4d65-b144-8bec4ec2e244",
   "metadata": {},
   "source": [
    "Since the dataset is big, CLT applies and this assumption holds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6173c0c7-d63d-48f7-a5d8-574f364f2a5a",
   "metadata": {},
   "source": [
    "## Check for Zero Mean of the Residuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603fff86-4f53-4a11-896c-f22a91393915",
   "metadata": {},
   "source": [
    "Since we won't omit a possible intercept the residuals should result to a zero mean. This assumption holds as well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746a27b7-96dc-4569-b7f7-17375853af6a",
   "metadata": {},
   "source": [
    "## Check for Homoscedasticity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c424441f-37be-44ed-8e1a-dcfdfa57c4c4",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "Checking the scatter plots of price VS the continuous variables it can be seen that the transformation of price to a logarithmic one, fixes this issue. The volume of engine VS log price might need a further inspection, however, we will suppose that this assumption holds as well.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da698900-ec95-46ad-b59a-c300fd763a47",
   "metadata": {},
   "source": [
    "## Check for No-Autocorellation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4c06c0-00c2-41c2-a073-3e1a5234bf6e",
   "metadata": {},
   "source": [
    "The residuals won't be showcased a specific pattern if plotted over time since the dataset provided isn't related to time. This assumption holds. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a02ed26-b83c-4ec7-8e16-77987fe5deac",
   "metadata": {},
   "source": [
    "## Check for Multicolinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0693a88-1a1e-449c-9747-547f8f231c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isolate the variables have to be checked for multicolinearity:\n",
    "cont_vars = df[['Mileage', 'Year', 'EngineV']]\n",
    "\n",
    "# Create an empty df and a column:\n",
    "vif = pd.DataFrame()\n",
    "vif['Features'] = cont_vars.columns\n",
    "\n",
    "# Calculate the vif values:\n",
    "vif[\"VIF\"] = [variance_inflation_factor(cont_vars.values, i) for i in range(cont_vars.shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f94f22c-250a-4b5f-b244-da8e22eee307",
   "metadata": {},
   "source": [
    "Considering that mileage might be corellated with year and since year has the biggest vif value we 'll drop the year column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a32b920-c989-4a80-91f5-4396781caa06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the year column:\n",
    "df = df.drop(columns='Year', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fec9b9c-6795-4b16-ac0a-7a6892293aa8",
   "metadata": {},
   "source": [
    "# Create Dummies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f85581b-e550-447a-8e8b-e659380ef1c6",
   "metadata": {},
   "source": [
    "We 'll drop the model column simplyfying the process because the brand, the mileage and the engine volume already include information which might be related to the model and won't lead to lost of variablity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca138f-8e18-485b-add0-03153d56a83c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the model column:\n",
    "df = df.drop(columns='Model', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbbcce2-4a7a-44fb-b59d-936d9c36c13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dummies:\n",
    "df_dummies = pd.get_dummies(df, drop_first=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88186f27-992f-40ee-a406-280f25eda3a9",
   "metadata": {},
   "source": [
    "# Linear Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dfd389a-7cdc-4e01-91ef-1cbffb300a05",
   "metadata": {},
   "source": [
    "## Define Features and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7adc8c7e-e1de-4a1b-a1d9-9845b6e897c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features:\n",
    "x = df_dummies.drop(columns='Price', axis=1)\n",
    "\n",
    "# Define the target:\n",
    "y = df_dummies['Price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b949497-3787-478f-aa82-af3786796217",
   "metadata": {},
   "source": [
    "## Scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfdf46a-ab29-4981-84eb-fd713c5a6e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the scaler instance and fit it with features:\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x)\n",
    "\n",
    "# Transform the features to scaled ones:\n",
    "x_scaled = scaler.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b4178a-040f-4f46-aa17-48c3932078dd",
   "metadata": {},
   "source": [
    "## Split the Data Avoiding Overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7170fa-3694-40ad-8667-a501f8414b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into two parts to avoid overfitting:\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_scaled, y, test_size=0.2, random_state=365)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bb3921-d62e-4f4a-a930-8a6bac04ea34",
   "metadata": {},
   "source": [
    "## Linear Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394d9b2-049e-46ac-8603-2e335f30848b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the linear regression instance:\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the instance with the training part of the data:\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Create predictions over the train part of the data to see how the model behaves in comparison to the train set: \n",
    "y_hat_train = model.predict(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04cf2272-4657-497f-b065-b1d2f34db023",
   "metadata": {},
   "source": [
    "## Model Results over the Training Set of the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a4e0d2-ef3f-43c3-92da-d5891cd8757e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of actual price versus predicted price:\n",
    "sns.scatterplot(x=y_train, y=y_hat_train, alpha=0.4, label='Predictions over the Train Set')\n",
    "\n",
    "# Set the labels:\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price from Train Set')\n",
    "plt.title('Actual Logarithmic Price VS Predicted Logarithmic Price over the Train Set')\n",
    "\n",
    "# Determine the min and max for the axes to plot the 45-degree line\n",
    "min_val = min(min(y_train), min(y_hat_train))\n",
    "max_val = max(max(y_train), max(y_hat_train))\n",
    "\n",
    "# Plot the 45-degree line (perfect prediction line)\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Hypothetical Perfect Fit')\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "plt.savefig('scatterplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "389b629c-6822-4140-9450-c0b679be41c2",
   "metadata": {},
   "source": [
    "The above scatter plot indicates that the model works. There is a pattern in predicted data which follows the hypothetical perfect fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbe556a-d233-41de-b3ef-12e976c3f78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histplot of the residuals:\n",
    "sns.histplot(y_train - y_hat_train, kde=True)\n",
    "\n",
    "# Create a helpline originated from zero:\n",
    "plt.axvline(x=0, color='red', linestyle='--')\n",
    "\n",
    "# Set the title and the x label:\n",
    "plt.xlabel('Logarithmic Price')\n",
    "plt.title('Probability Density Function for Residuals over the Train Set');\n",
    "\n",
    "plt.savefig('histplot.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce50fc09-8215-4c6c-8d53-c172f30175e7",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "The actual logarithmic price over the predicted logarithmic price implied that there might be a possibility the model can be further improved. The probability density function of the logarithmic price residuals confirms this. To be more specific, it can be seen that there are some predictions far above the actual price, whereas the majority of the predictions have underestimated the price (the red line is slightly at the left affecting the normal distribution and meaning there are a lot of predicted data at its right).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29223c86-bcb0-46b5-aaf5-4d638c81a4c2",
   "metadata": {},
   "source": [
    "## Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423859d0-b36e-4bfc-96f8-746b0d8da89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feature_summary = pd.DataFrame(x.columns.values, columns=['Features'])\n",
    "train_feature_summary['Weights'] = model.coef_\n",
    "train_feature_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10c79a8-8835-45e8-a62a-42accbca7763",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = model.score(x_train, y_train)\n",
    "r2_adj = 1 - (1 - r2)* (x.shape[0] - 1) / (x.shape[0] - x.shape[1] -1)\n",
    "param_summary = pd.DataFrame([\n",
    "    {'Parameters': 'Intercept', 'Values': model.intercept_},\n",
    "    {'Parameters': 'R-Squared', 'Values': r2},\n",
    "    {'Parameters': ' Adj R-Squared', 'Values': r2_adj}])\n",
    "param_summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e2b231-290e-469a-a32a-881a4b1df4bb",
   "metadata": {},
   "source": [
    "## Predictions of the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fcbd9e-c0ac-4f94-8199-b36d2f6778e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b392f85-a35d-4101-8138-eddac9e3b2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of actual price versus predicted price:\n",
    "sns.scatterplot(x=y_test, y=y_hat_test, alpha=0.4, label='Predictions over the Test Set')\n",
    "\n",
    "# Set the labels:\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price from Test Set')\n",
    "plt.title('Actual Logarithmic Price VS Predicted Logarithmic Price over the Test Set')\n",
    "\n",
    "# Determine the min and max for the axes to plot the 45-degree line\n",
    "min_val = min(min(y_test), min(y_hat_test))\n",
    "max_val = max(max(y_test), max(y_hat_test))\n",
    "\n",
    "# Plot the 45-degree line (perfect prediction line)\n",
    "plt.plot([min_val, max_val], [min_val, max_val], color='red', linestyle='--', label='Hypothetical Perfect Fit')\n",
    "\n",
    "plt.legend();\n",
    "\n",
    "plt.savefig('scatterplot2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55868e5-4df4-4465-b781-ec6584cd3834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a histplot of the residuals:\n",
    "sns.histplot(y_test - y_hat_test, kde=True)\n",
    "\n",
    "# Create a helpline originated from zero:\n",
    "plt.axvline(x=0, color='red', linestyle='--', label='Zero Mean Helpline')\n",
    "\n",
    "# Set title, axis labels and legend:\n",
    "plt.xlabel('Logarithmic Price')\n",
    "plt.title('Probability Density Function of Residuals over Test Set');\n",
    "plt.legend();\n",
    "\n",
    "plt.savefig('histplot2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b01b479-6a6d-45c7-95df-c9b54104aa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a scatter plot of predicted price versus residuals over the test set:\n",
    "sns.scatterplot(x=y_hat_test, y=y_test - y_hat_test, alpha=0.4, label='Residuals over the Test Set')\n",
    "\n",
    "# Add a horizontal line at y=0 to indicate the zero residuals line:\n",
    "plt.axhline(0, color='red', linestyle='--', label='Zero Residuals Line')\n",
    "\n",
    "# Set title, axis labels and legend:\n",
    "plt.xlabel('Price Predictions')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Logarithmic Price Predictions VS Residuals over the Test Set');\n",
    "plt.legend();\n",
    "\n",
    "plt.savefig('scatterplot3.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08396e4f-a7df-4a61-8043-a3e71f0e3fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn the logarithmic price into a normal one:\n",
    "predictions = np.exp(y_hat_test)\n",
    "actual_price = np.exp(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204dfe68-f2e1-43c7-9d42-a63b96f5aa8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new df adding the predictions to a columns:\n",
    "df_comparison = pd.DataFrame(predictions, columns=['Predictions'])\n",
    "\n",
    "# Fix the index before adding the actual prices to the same df:\n",
    "actual_price = actual_price.reset_index(drop=True)\n",
    "\n",
    "# Add the actual prices next to predicted prices:\n",
    "df_comparison['Actual Prices'] = actual_price\n",
    "\n",
    "# Add residuals column:\n",
    "df_comparison['Residuals'] = df_comparison['Actual Prices'] - df_comparison['Predictions']\n",
    "\n",
    "# Add percentage of difference column:\n",
    "df_comparison['Difference %'] = np.abs(round((df_comparison['Residuals'] / df_comparison['Actual Prices']) * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57af3c61-c7b4-4667-9f86-b22e6a1b7158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort values by difference in actual vs predicted price:\n",
    "df_comparison.sort_values(by='Difference %', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ecceed-f844-4b58-95f0-a266210b0f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'model_performance_dataframe.csv'\n",
    "df.to_csv(file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4172de7a-f0f6-4511-b5c0-f81698a32ba9",
   "metadata": {},
   "source": [
    "# Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54be4ad-254b-45ad-b182-407dd28130e5",
   "metadata": {},
   "source": [
    "<div style=\"text-align: justify\">\n",
    "The model isn't bad, but isn't good neither. Additionally, the column 'Difference %' might misleads information. It doesn't punish the cases where the model underestimates price with the same effect it punishes the cases which the model overestimates price. I am also quetsioning the absolute value in this column which hides even more information. There are a lot of things can be done here:  \n",
    "    \n",
    "1) The data frame with the comparisons (df_comparison) might need further improvements or probably the creation of a function which will display more metrics than the 'Difference %'.\n",
    "2) Delving into the model and understand 100% its results.\n",
    "3) Apply improvements (feature selection, different data transformations etc) using the same model (Linear Regression) and see what happens, trying to better understand the results.\n",
    "4) Getting in more advanced projects might require the creation of some appropriate functions in order to copy them and use them repeatidly and quickly in my future projects.\n",
    "\n",
    "Since this is a lot of work, it may be wiser to be done at the future. This notebook is already big enough and includes so much information. In addition, proceeding to other parts of my study might reveal some of the knowledge I lack at this moment and directly help me solve some of my ambiguities here. \n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
